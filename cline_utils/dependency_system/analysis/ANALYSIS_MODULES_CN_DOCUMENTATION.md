# Analysis æ¨¡å—è¯¦ç»†ä¸­æ–‡æ–‡æ¡£
# Analysis Modules - Detailed Chinese Documentation

> **åˆ›å»ºæ—¥æœŸ**: 2025-12-15
> **æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
> **é€‚ç”¨ç³»ç»Ÿ**: Cline Recursive Chain-of-Thought System (CRCT)

---

## ğŸ“‹ ç›®å½• (Table of Contents)

1. [æ¨¡å—æ¦‚è¿°](#æ¨¡å—æ¦‚è¿°)
2. [project_analyzer.py - é¡¹ç›®åˆ†æå™¨](#1-project_analyzerpy---é¡¹ç›®åˆ†æå™¨)
3. [embedding_manager.py - åµŒå…¥ç®¡ç†å™¨](#2-embedding_managerpy---åµŒå…¥ç®¡ç†å™¨)
4. [dependency_analyzer.py - ä¾èµ–åˆ†æå™¨](#3-dependency_analyzerpy---ä¾èµ–åˆ†æå™¨)
5. [dependency_suggester.py - ä¾èµ–å»ºè®®å™¨](#4-dependency_suggesterpy---ä¾èµ–å»ºè®®å™¨)
6. [æ•°æ®æµç¨‹å›¾](#æ•°æ®æµç¨‹å›¾)
7. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ¨¡å—æ¦‚è¿°

### ç³»ç»Ÿæ¶æ„ (System Architecture)

åˆ†ææ¨¡å—æ˜¯æ•´ä¸ªCRCTä¾èµ–ç³»ç»Ÿçš„æ ¸å¿ƒ,ç”±å››ä¸ªä¸»è¦æ¨¡å—ç»„æˆ:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROJECT ANALYZER                       â”‚
â”‚                  (é¡¹ç›®åˆ†æå™¨ - æ€»åè°ƒå™¨)                    â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   EMBEDDING  â”‚  â”‚  DEPENDENCY  â”‚  â”‚  DEPENDENCY  â”‚  â”‚
â”‚  â”‚   MANAGER    â”‚  â”‚   ANALYZER   â”‚  â”‚  SUGGESTER   â”‚  â”‚
â”‚  â”‚  (åµŒå…¥ç®¡ç†å™¨)  â”‚  â”‚  (ä¾èµ–åˆ†æå™¨) â”‚  â”‚  (ä¾èµ–å»ºè®®å™¨) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                  â†“                  â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vectors â”‚      â”‚ AST Tree â”‚      â”‚ Suggested â”‚
    â”‚ Embeddingsâ”‚    â”‚ Analysis â”‚      â”‚Dependenciesâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒèŒè´£åˆ†å·¥

| æ¨¡å— | èŒè´£ | è¾“å…¥ | è¾“å‡º |
|-----|------|------|------|
| **project_analyzer** | æ€»åè°ƒå™¨,ç¼–æ’æ•´ä¸ªåˆ†ææµç¨‹ | é¡¹ç›®è·¯å¾„, é…ç½® | å®Œæ•´åˆ†æç»“æœ |
| **embedding_manager** | ç”Ÿæˆå’Œç®¡ç†æ–‡ä»¶åµŒå…¥å‘é‡ | æ–‡ä»¶å†…å®¹, ç¬¦å·æ˜ å°„ | å‘é‡è¡¨ç¤º |
| **dependency_analyzer** | è§£ææ–‡ä»¶,æå–ä¾èµ–ä¿¡æ¯ | æºæ–‡ä»¶ | ASTåˆ†æç»“æœ |
| **dependency_suggester** | å»ºè®®ä¾èµ–å…³ç³» | åˆ†æç»“æœ, åµŒå…¥ | ä¾èµ–å»ºè®®åˆ—è¡¨ |

---

## 1. project_analyzer.py - é¡¹ç›®åˆ†æå™¨

### ğŸ“– æ¨¡å—è¯´æ˜

**æ–‡ä»¶**: `cline_utils/dependency_system/analysis/project_analyzer.py`
**è¡Œæ•°**: ~1,409 è¡Œ
**æ ¸å¿ƒåŠŸèƒ½**: æ•´ä¸ªä¾èµ–åˆ†æç³»ç»Ÿçš„æ€»åè°ƒå™¨å’Œå…¥å£ç‚¹

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

#### 1.1 ä¸»å‡½æ•°: `analyze_project()`

**å‡½æ•°ç­¾å**:
```python
def analyze_project(
    force_analysis: bool = False,
    force_embeddings: bool = False
) -> Dict[str, Any]:
```

**å®Œæ•´å·¥ä½œæµç¨‹**:

```
1. åˆå§‹åŒ–è®¾ç½®
   â”œâ”€ é‡ç½®ç»Ÿè®¡ä¿¡æ¯
   â”œâ”€ åŠ è½½é…ç½®
   â””â”€ ç¡®å®šé¡¹ç›®æ ¹ç›®å½•

2. å¯†é’¥ç”Ÿæˆé˜¶æ®µ
   â”œâ”€ ä¸ºæ‰€æœ‰æ–‡ä»¶/ç›®å½•ç”Ÿæˆå”¯ä¸€å¯†é’¥
   â”œâ”€ å¤„ç†è·¯å¾„è¿ç§»
   â””â”€ æ£€æµ‹æ–°å¢å¯†é’¥

3. æ–‡ä»¶è¯†åˆ«ä¸è¿‡æ»¤
   â”œâ”€ åº”ç”¨æ’é™¤è§„åˆ™
   â”œâ”€ è¯†åˆ«ä»£ç æ ¹ç›®å½•
   â””â”€ æ„å»ºæ–‡ä»¶åˆ—è¡¨

4. æ–‡ä»¶åˆ†æé˜¶æ®µ (å¹¶è¡Œ)
   â”œâ”€ Python: AST + Tree-sitter
   â”œâ”€ JavaScript/TypeScript: Tree-sitter
   â”œâ”€ HTML/CSS: Tree-sitter
   â””â”€ Markdown: Regex

5. ç¬¦å·æ˜ å°„ç”Ÿæˆ
   â”œâ”€ æ”¶é›†æ‰€æœ‰ç¬¦å·å®šä¹‰
   â”œâ”€ åˆå¹¶è¿è¡Œæ—¶ç¬¦å·
   â”œâ”€ éªŒè¯ç¬¦å·å®Œæ•´æ€§
   â””â”€ ä¿å­˜ç¬¦å·æ˜ å°„æ–‡ä»¶

6. åµŒå…¥å‘é‡ç”Ÿæˆ
   â”œâ”€ ç”ŸæˆSES (Symbol Essence String)
   â”œâ”€ é€‰æ‹©æœ€ä½³æ¨¡å‹
   â”œâ”€ æ‰¹é‡ç¼–ç 
   â””â”€ æŒä¹…åŒ–å‘é‡

7. ä¾èµ–å»ºè®®é˜¶æ®µ (å¹¶è¡Œ)
   â”œâ”€ ç»“æ„åŒ–ä¾èµ–è¯†åˆ«
   â”œâ”€ è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
   â”œâ”€ ASTéªŒè¯é“¾æ¥
   â””â”€ å­—ç¬¦æ ‡è®°åˆ†é…

8. è·Ÿè¸ªå™¨æ›´æ–°
   â”œâ”€ Miniè·Ÿè¸ªå™¨ (æ¨¡å—çº§)
   â”œâ”€ Docè·Ÿè¸ªå™¨ (æ–‡æ¡£)
   â””â”€ Mainè·Ÿè¸ªå™¨ (é¡¹ç›®çº§)

9. æ¨¡æ¿ç”Ÿæˆ
   â””â”€ æœ€ç»ˆå®¡æŸ¥æ¸…å•

10. è‡ªåŠ¨å¯è§†åŒ–
    â”œâ”€ é¡¹ç›®æ¦‚è§ˆå›¾
    â””â”€ æ¨¡å—çº§è¯¦ç»†å›¾
```

#### 1.2 å…³é”®æ•°æ®ç»“æ„

**åˆ†æç»“æœå­—å…¸ (analysis_results)**:
```python
{
    "status": str,              # success/warning/error/skipped
    "message": str,             # çŠ¶æ€æ¶ˆæ¯
    "warnings": List[str],      # è­¦å‘Šåˆ—è¡¨
    "key_generation": {
        "count": int,           # ç”Ÿæˆçš„å¯†é’¥æ€»æ•°
        "new_count": int,       # æ–°ç”Ÿæˆçš„å¯†é’¥æ•°é‡
    },
    "embedding_generation": {
        "status": str,          # åµŒå…¥ç”ŸæˆçŠ¶æ€
    },
    "dependency_suggestion": {
        "status": str,          # ä¾èµ–å»ºè®®çŠ¶æ€
        "suggestion_count": int,  # å»ºè®®æ€»æ•°
        "ast_link_count": int,   # ASTéªŒè¯é“¾æ¥æ•°é‡
    },
    "tracker_updates": {
        "mini": Dict,           # Miniè·Ÿè¸ªå™¨æ›´æ–°ç»“æœ
        "doc": str,             # Docè·Ÿè¸ªå™¨æ›´æ–°çŠ¶æ€
        "main": str,            # Mainè·Ÿè¸ªå™¨æ›´æ–°çŠ¶æ€
    },
    "file_analysis": Dict,      # æ–‡ä»¶åˆ†æç»“æœæ˜ å°„
    "template_generation": Dict, # æ¨¡æ¿ç”Ÿæˆç»“æœ
    "auto_visualization": Dict,  # å¯è§†åŒ–ç»“æœ
    "symbol_map_generation": {
        "status": str,          # ç¬¦å·æ˜ å°„ç”ŸæˆçŠ¶æ€
        "path": str,            # ç¬¦å·æ˜ å°„æ–‡ä»¶è·¯å¾„
        "count": int,           # ç¬¦å·æ˜ å°„æ¡ç›®æ•°é‡
        "validation_summary": Dict,  # éªŒè¯æ‘˜è¦
    },
    "ast_verified_links_generation": {
        "status": str,          # ASTé“¾æ¥ç”ŸæˆçŠ¶æ€
        "path": str,            # ASTé“¾æ¥æ–‡ä»¶è·¯å¾„
        "count": int,           # ASTé“¾æ¥æ•°é‡
    }
}
```

#### 1.3 å…³é”®å‡½æ•°è¯¦è§£

##### `_is_empty_dir(dir_path, tracker_filename_to_ignore)`

**åŠŸèƒ½**: æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º(ç”¨äºè·Ÿè¸ªå™¨åˆ›å»º)

**é€»è¾‘**:
```python
def _is_empty_dir(dir_path, tracker_filename_to_ignore=None):
    """
    æ£€æŸ¥é€»è¾‘:
    1. åˆ—å‡ºç›®å½•å†…å®¹
    2. å¦‚æœå®Œå…¨ä¸ºç©º -> True
    3. å¦‚æœåªåŒ…å«è·Ÿè¸ªå™¨æ–‡ä»¶æœ¬èº« -> True
    4. å¦‚æœåŒ…å«å…¶ä»–æ–‡ä»¶ -> False
    5. é”™è¯¯æƒ…å†µ(ä¸å­˜åœ¨/æƒé™) -> True (å®‰å…¨èµ·è§)
    """
```

#### 1.4 é…ç½®æ–‡ä»¶å¸¸é‡

```python
# ç¬¦å·æ˜ å°„æ–‡ä»¶
PROJECT_SYMBOL_MAP_FILENAME = "project_symbol_map.json"
OLD_PROJECT_SYMBOL_MAP_FILENAME = "project_symbol_map_old.json"

# ASTéªŒè¯é“¾æ¥æ–‡ä»¶
AST_VERIFIED_LINKS_FILENAME = "ast_verified_links.json"
OLD_AST_VERIFIED_LINKS_FILENAME = "ast_verified_links_old.json"
```

### ğŸ”„ å·¥ä½œæµç¨‹è¯¦ç»†è¯´æ˜

#### é˜¶æ®µ1: å¯†é’¥ç”Ÿæˆ
```python
# è°ƒç”¨key_managerç”Ÿæˆå¯†é’¥
path_to_key_info, newly_generated_keys = key_manager.generate_keys(
    all_roots_rel,                    # æ‰€æœ‰æ ¹ç›®å½•
    excluded_dirs=excluded_dirs_rel,  # æ’é™¤ç›®å½•
    excluded_extensions=excluded_extensions,  # æ’é™¤æ‰©å±•å
    precomputed_excluded_paths=all_excluded_paths_abs_set  # é¢„è®¡ç®—çš„æ’é™¤è·¯å¾„
)
```

**è¿”å›å€¼**:
- `path_to_key_info`: Dict[str, KeyInfo] - è·¯å¾„åˆ°å¯†é’¥ä¿¡æ¯çš„æ˜ å°„
- `newly_generated_keys`: List[KeyInfo] - æ–°ç”Ÿæˆçš„å¯†é’¥åˆ—è¡¨

#### é˜¶æ®µ2: è·¯å¾„è¿ç§»æ˜ å°„
```python
# æ„å»ºè·¯å¾„è¿ç§»æ˜ å°„(å¤„ç†å¯†é’¥å˜æ›´)
path_migration_info = tracker_io.build_path_migration_map(
    old_global_map,      # æ—§çš„å¯†é’¥æ˜ å°„
    path_to_key_info     # æ–°çš„å¯†é’¥æ˜ å°„
)
```

#### é˜¶æ®µ3: æ–‡ä»¶åˆ†æ(å¹¶è¡Œ)
```python
# ä½¿ç”¨æ‰¹å¤„ç†å™¨å¹¶è¡Œåˆ†ææ–‡ä»¶
analysis_results_list = process_items(
    files_to_analyze_abs,  # æ–‡ä»¶åˆ—è¡¨
    analyze_file,          # åˆ†æå‡½æ•°
    force=force_analysis   # å¼ºåˆ¶åˆ†ææ ‡å¿—
)
```

#### é˜¶æ®µ4: ç¬¦å·æ˜ å°„åˆå¹¶
```python
# åŠ è½½è¿è¡Œæ—¶ç¬¦å·
runtime_symbols = load_runtime_symbols(project_root)

# åˆå¹¶è¿è¡Œæ—¶(ä¼˜å…ˆ)å’ŒAST(å¢å¼º)
merged_symbol_map = merge_runtime_and_ast(
    runtime_symbols,      # ä¸»è¦æ¥æº
    project_symbol_data   # å¢å¼ºæ¥æº
)

# éªŒè¯åˆå¹¶è¾“å‡º
validation_results = validate_merged_output(merged_symbol_map)
```

#### é˜¶æ®µ5: åµŒå…¥ç”Ÿæˆ
```python
# ç¡®å®šæœ€ä½³æ‰¹æ¬¡å¤§å°
optimal_batch = get_optimal_batch_size()

# ç”ŸæˆåµŒå…¥
success = generate_embeddings(
    all_roots_rel,        # æ ¹ç›®å½•åˆ—è¡¨
    path_to_key_info,     # å¯†é’¥ä¿¡æ¯æ˜ å°„
    force=force_embeddings,  # å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ ‡å¿—
    batch_size=optimal_batch  # æ‰¹æ¬¡å¤§å°
)
```

#### é˜¶æ®µ6: ä¾èµ–å»ºè®®(å¹¶è¡Œ+å…±äº«è®¡æ•°å™¨)
```python
import multiprocessing

# åˆ›å»ºå…±äº«è®¡æ•°å™¨(çº¿ç¨‹å®‰å…¨)
shared_scan_counter = multiprocessing.Value("i", 0)

# åŒ…è£…å™¨å‡½æ•°
def _suggest_wrapper(single_file_path, ...):
    suggs, ast_links = suggest_dependencies(
        single_file_path,
        path_to_key_info_map,
        project_root_abs,
        file_analysis_blob,
        doc_similarity_threshold,
        shared_scan_counter=shared_scan_counter  # å…±äº«è®¡æ•°å™¨
    )
    return (single_file_path, suggs, ast_links)

# å¹¶è¡Œå¤„ç†
suggestion_results = suggestion_batcher.process_items(
    analyzed_file_paths,
    _suggest_wrapper,
    ...
)
```

#### é˜¶æ®µ7: è·¯å¾„åŸºç¡€å»ºè®®è½¬æ¢ä¸ºå¯†é’¥æ ¼å¼
```python
# è½¬æ¢è·¯å¾„åŸºç¡€å»ºè®®ä¸ºKEY#global_instanceæ ¼å¼
for src_path, path_deps_list in combined_path_suggestions.items():
    src_ki = current_global_map.get(src_path)
    src_key_global_instance_str = get_key_global_instance_string(
        src_ki,
        current_global_map,
        cache
    )
    # ...å¤„ç†æ¯ä¸ªç›®æ ‡ä¾èµ–
```

#### é˜¶æ®µ8: è·Ÿè¸ªå™¨æ›´æ–°

**Miniè·Ÿè¸ªå™¨** (æ¨¡å—çº§):
```python
# è¯†åˆ«æ‰€æœ‰æ¨¡å—ç›®å½•
for ki_obj in path_to_key_info.values():
    if ki_obj.is_directory and is_module_dir:
        # æ›´æ–°miniè·Ÿè¸ªå™¨
        tracker_io.update_tracker(
            output_file_suggestion=mini_tracker_path,
            path_to_key_info=path_to_key_info,
            tracker_type="mini",
            suggestions_external=all_global_instance_suggestions,
            force_apply_suggestions=True  # å¼ºåˆ¶åº”ç”¨å»ºè®®
        )
```

**Docè·Ÿè¸ªå™¨**:
```python
if doc_tracker_path:
    tracker_io.update_tracker(
        output_file_suggestion=doc_tracker_path,
        tracker_type="doc",
        ...
    )
```

**Mainè·Ÿè¸ªå™¨** (ä½¿ç”¨èšåˆ):
```python
tracker_io.update_tracker(
    output_file_suggestion=main_tracker_path,
    tracker_type="main",  # ä¼šè§¦å‘å†…éƒ¨èšåˆ
    ...
)
```

#### é˜¶æ®µ9: è‡ªåŠ¨å¯è§†åŒ–
```python
if auto_generate_enabled:
    # 1. é¢„èšåˆä¾èµ–(ä¸€æ¬¡æ€§,æ‰€æœ‰å›¾å…±äº«)
    project_aggregated_links = aggregate_all_dependencies(
        set(current_tracker_paths),
        path_migration_info,
        path_to_key_info
    )

    # 2. ç”Ÿæˆé¡¹ç›®æ¦‚è§ˆå›¾
    overview_mermaid_code = generate_mermaid_diagram(
        focus_keys_list_input=[],  # ç©ºåˆ—è¡¨=æ¦‚è§ˆ
        global_path_to_key_info_map=path_to_key_info,
        pre_aggregated_links=project_aggregated_links
    )

    # 3. ä¸ºæ¯ä¸ªé¡¶çº§æ¨¡å—ç”Ÿæˆè¯¦ç»†å›¾
    for module_key_str in module_keys_unique:
        module_mermaid_code = generate_mermaid_diagram(
            focus_keys_list_input=[module_key_str],
            pre_aggregated_links=project_aggregated_links
        )
```

### ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. æ‰¹å¤„ç† (Batching)
```python
# æ–‡ä»¶åˆ†æ: å¹¶è¡Œæ‰¹å¤„ç†
analysis_results_list = process_items(
    files_to_analyze_abs,
    analyze_file,
    force=force_analysis
)

# åµŒå…¥ç”Ÿæˆ: æŒ‰tokenæ•°æ’åº,åŠ¨æ€æ‰¹æ¬¡
processing_queue.sort(key=lambda x: x["tokens"])
```

#### 2. ç¼“å­˜ç­–ç•¥
```python
# æ–‡ä»¶çº§ç¼“å­˜ (åŸºäºmtime)
@cached("file_analysis",
    key_func=lambda file_path, force=False:
        f"analyze_file:{normalize_path(file_path)}:"
        f"{os.path.getmtime(file_path)}:{force}"
)

# æ¸…é™¤ç¼“å­˜
if force_analysis:
    clear_all_caches()
```

#### 3. å†…å­˜ç®¡ç†
```python
# ASTç¼“å­˜æ¸…ç†(åœ¨åˆ†æç»“æŸæ—¶)
ast_cache_instance = cache_manager.get_cache("ast_cache")
ast_cache_instance.data.clear()
logger.info("Cleared in-memory AST cache")
```

#### 4. å…±äº«èµ„æº
```python
# å…±äº«æ‰«æè®¡æ•°å™¨(é¿å…å…¨å±€å˜é‡ç«æ€)
shared_scan_counter = multiprocessing.Value("i", 0)

# å…±äº«é¢„èšåˆç»“æœ(é¿å…é‡å¤èšåˆ)
project_aggregated_links = aggregate_all_dependencies(...)
# æ‰€æœ‰å›¾å…±äº«è¿™ä¸ªç»“æœ
```

### âš ï¸ é”™è¯¯å¤„ç†

#### 1. åˆ†çº§é”™è¯¯å¤„ç†
```python
try:
    # å…³é”®æ“ä½œ
except SpecificError as e:
    # ç‰¹å®šé”™è¯¯å¤„ç†
    analysis_results["status"] = "error"
    return analysis_results
except Exception as e:
    # é€šç”¨é”™è¯¯å¤„ç†
    logger.exception(f"Unexpected error: {e}")
    analysis_results["status"] = "error"
    return analysis_results
```

#### 2. éƒ¨åˆ†å¤±è´¥å®¹å¿
```python
# å…è®¸éƒ¨åˆ†æ–‡ä»¶å¤±è´¥
for file_path, analysis_result in ...:
    if "error" in analysis_result:
        error_count += 1  # è®¡æ•°ä½†ç»§ç»­
    else:
        analyzed_count += 1
```

#### 3. çŠ¶æ€é™çº§
```python
# è­¦å‘Šä¸é˜»æ­¢æµç¨‹
if not success:
    analysis_results["warnings"].append("Embedding generation partial failure")
    analysis_results["status"] = "warning"  # é™çº§,ä¸æ˜¯error
```

---

## 2. embedding_manager.py - åµŒå…¥ç®¡ç†å™¨

### ğŸ“– æ¨¡å—è¯´æ˜

**æ–‡ä»¶**: `cline_utils/dependency_system/analysis/embedding_manager.py`
**è¡Œæ•°**: ~1,704 è¡Œ
**æ ¸å¿ƒåŠŸèƒ½**: ç®¡ç†æ–‡ä»¶åµŒå…¥å‘é‡çš„ç”Ÿæˆã€å­˜å‚¨å’Œç›¸ä¼¼åº¦è®¡ç®—

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

#### 2.1 æ¨¡å‹é€‰æ‹©ç³»ç»Ÿ

**æ”¯æŒçš„æ¨¡å‹**:

| æ¨¡å‹å | ç±»å‹ | ç»´åº¦ | æœ€å°VRAM | æœ€å°RAM | ä¸Šä¸‹æ–‡é•¿åº¦ |
|-------|------|------|----------|---------|-----------|
| **Qwen3-4B** | GGUF (Q6_Ké‡åŒ–) | 2560 | 3.5GB | 6.0GB | 32768 |
| **all-mpnet-base-v2** | SentenceTransformer | 384 | 0.5GB | 2.0GB | 512 |

**è‡ªåŠ¨é€‰æ‹©é€»è¾‘**:
```python
def _select_best_model() -> Dict[str, Any]:
    """
    é€‰æ‹©é€»è¾‘:
    1. æ£€æŸ¥é…ç½®æŒ‡å®š: model_selection = "qwen3-4b" / "mpnet" / "auto"
    2. å¦‚æœauto:
       a. æ£€æµ‹è®¾å¤‡(CUDA/MPS/CPU)
       b. æµ‹é‡å¯ç”¨å†…å­˜
       c. å¦‚æœå†…å­˜è¶³å¤Ÿ -> Qwen3-4B
       d. å¦åˆ™ -> all-mpnet-base-v2
    3. ä¸‹è½½æ¨¡å‹(å¦‚æœä¸å­˜åœ¨)
    4. éªŒè¯æ¨¡å‹å®Œæ•´æ€§
    """
```

**è®¾å¤‡é€‰æ‹©**:
```python
def _get_best_device() -> str:
    """
    è®¾å¤‡ä¼˜å…ˆçº§:
    1. CUDA (æœ€é«˜ä¼˜å…ˆçº§,å¦‚æœå¯ç”¨)
       - æµ‹è¯•å¼ é‡åˆ›å»º
       - æ¸…ç©ºç¼“å­˜
    2. MPS (Apple Silicon)
       - æ£€æŸ¥å¹³å°å’Œå¯ç”¨æ€§
       - æµ‹è¯•å¼ é‡åˆ›å»º
    3. CPU (åå¤‡)
    """
```

#### 2.2 Symbol Essence String (SES) ç”Ÿæˆ

**SESç»“æ„**:
```
[FILE: ç›¸å¯¹è·¯å¾„ | TYPE: æ–‡ä»¶ç±»å‹ | MOD: ä¿®æ”¹æ—¶é—´]

CLASS: ClassName
  BASES: BaseClass1, BaseClass2
  DECORATORS: @decorator1, @decorator2
  DOC: ç±»æ–‡æ¡£å­—ç¬¦ä¸²
  METHOD: method_name(param1, param2)
    DOC: æ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²
    TYPES: param1=str, param2=int
    GLOBALS: global_var1, global_var2
    ACCESSES: attr1, attr2

FUNCTIONS:
  function_name(param1, param2)
    DOC: å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²
    TYPES: param1=List[str], return=Dict
    GLOBALS: config, logger

CALLS: func1, module.func2, ClassName.method

CALLED_BY: file1.py, file2.py, package/file3.py
```

**ç”Ÿæˆå‡½æ•°**:
```python
def generate_symbol_essence_string(
    file_path: str,
    symbol_data: Dict[str, Any],
    max_chars: int = 4000,
    symbol_map: Optional[Dict[str, Any]] = None
) -> str:
    """
    ç”Ÿæˆç­–ç•¥:
    1. æ–‡ä»¶å¤´éƒ¨ (è·¯å¾„,ç±»å‹,ä¿®æ”¹æ—¶é—´)
    2. ç±»å®šä¹‰ (è¿è¡Œæ—¶å¢å¼º)
       - ç»§æ‰¿å±‚æ¬¡
       - è£…é¥°å™¨é“¾
       - ç±»å‹æ³¨è§£
    3. æ–¹æ³•/å‡½æ•° (è¿è¡Œæ—¶ç­¾åä¼˜å…ˆ)
       - å®Œæ•´ç­¾å
       - ä½œç”¨åŸŸå¼•ç”¨
       - å±æ€§è®¿é—®æ¨¡å¼
    4. è°ƒç”¨å›¾ (ASTæå–)
    5. åå‘å¼•ç”¨ (CALLED_BY)
    6. æˆªæ–­è‡³max_chars
    """
```

#### 2.3 Qwen3 Reranker é›†æˆ

**Rerankeræ¨¡å‹é…ç½®**:
```python
RERANKER_REPO_ID = "ManiKumarAdapala/Qwen3-Reranker-0.6B-Q8_0-Safetensors"
RERANKER_FILES = [
    "model.safetensors",
    "config.json",
    "tokenizer.json",
    "tokenizer_config.json",
    "special_tokens_map.json",
]
```

**Rerankingæµç¨‹**:
```python
def rerank_candidates_with_qwen3(
    query_text: str,
    candidate_texts: List[str],
    top_k: int = 10,
    source_file_path: Optional[str] = None,
    instruction: Optional[str] = None
) -> List[Tuple[int, float]]:
    """
    Rerankingæµç¨‹:
    1. åŠ è½½Tokenizerå’Œæ¨¡å‹
    2. æ„å»ºPrompt (ç³»ç»ŸæŒ‡ä»¤æ ¼å¼):
       <|im_start|>system
       Judge whether the Document meets the requirements...
       <|im_end|>
       <|im_start|>user
       <Instruct>: [æŒ‡ä»¤]
       <Query>: [æŸ¥è¯¢]
       <Document>: [æ–‡æ¡£]
       <|im_end|>
       <|im_start|>assistant
       <think>

       </think>

    3. Tokenizeæ‰€æœ‰å€™é€‰
    4. æŒ‰é•¿åº¦æ’åº(çŸ­çš„å…ˆå¤„ç†)
    5. åŠ¨æ€æ‰¹å¤„ç†:
       - è®¡ç®—å¯ç”¨å†…å­˜
       - æ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦è°ƒæ•´æ‰¹æ¬¡å¤§å°
       - æŒ‰æ‰¹æ¬¡å¤„ç†
    6. æå–yes/no token logits
    7. è®¡ç®—æ¦‚ç‡åˆ†æ•°
    8. æ’åºè¿”å›top_k
    """
```

**åŠ¨æ€æ‰¹æ¬¡å¤§å°è®¡ç®—**:
```python
def _calculate_dynamic_batch_size(
    available_mem_gb: float,
    context_length: int,
    device: str
) -> int:
    """
    ç»éªŒå…¬å¼ (åŸºäºRTX 4060 8GBå®æµ‹):
    - æ¨¡å‹å ç”¨: ~1.1GB
    - Context=1000: ~0.3GB/æ ·æœ¬ -> Batch=15
    - Context=4000: ~0.5GB/æ ·æœ¬ -> Batch=8
    - Context=8000: ~0.8GB/æ ·æœ¬ -> Batch=5
    - Context=16000: ~1.5GB/æ ·æœ¬ -> Batch=3
    - Context=32000: ~2.5GB/æ ·æœ¬ -> Batch=2

    å…¬å¼:
    MB_per_sample = 175 + (context_length/1000) * 80
    usable_mem = available_mem * 0.8  # ä¿ç•™20%ç¼“å†²
    batch_size = min(50, max(1, usable_mem / GB_per_sample))
    """
```

#### 2.4 åµŒå…¥ç”Ÿæˆä¸»æµç¨‹

```python
def generate_embeddings(
    project_paths: List[str],
    path_to_key_info: Dict[str, KeyInfo],
    force: bool = False,
    batch_size: Optional[int] = None,
    symbol_map: Optional[Dict[str, Any]] = None
) -> bool:
    """
    åµŒå…¥ç”Ÿæˆæµç¨‹:

    1. å‡†å¤‡é˜¶æ®µ:
       â”œâ”€ åŠ è½½ç¬¦å·æ˜ å°„
       â”œâ”€ è¯†åˆ«éœ€è¦å¤„ç†çš„æ–‡ä»¶
       â””â”€ æ£€æŸ¥ç°æœ‰åµŒå…¥(mtimeæ¯”è¾ƒ)

    2. é¢„å¤„ç†é˜¶æ®µ:
       â”œâ”€ ç”ŸæˆSESæˆ–é¢„å¤„ç†æ–‡æ¡£
       â”œâ”€ è®¡ç®—tokenæ•°
       â”œâ”€ æŒ‰tokenæ•°æ’åº(é€’å¢)
       â””â”€ æ„å»ºå¤„ç†é˜Ÿåˆ—

    3. æ¨¡å‹åŠ è½½:
       â”œâ”€ é€‰æ‹©æœ€ä½³æ¨¡å‹
       â”œâ”€ ç¡®å®šè®¾å¤‡
       â””â”€ æ ¹æ®éœ€è¦åŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡çª—å£

    4. æ‰¹å¤„ç†ç¼–ç :
       â”œâ”€ æŒ‰æ‰¹æ¬¡å¤§å°åˆ†ç»„
       â”œâ”€ ç¼–ç æ‰¹æ¬¡
       â”œâ”€ å½’ä¸€åŒ–å‘é‡
       â””â”€ ä¿å­˜åˆ°.npyæ–‡ä»¶

    5. å…ƒæ•°æ®æ›´æ–°:
       â”œâ”€ æ›´æ–°metadata.json
       â”œâ”€ è®°å½•æ¨¡å‹ç‰ˆæœ¬
       â””â”€ è®°å½•æ–‡ä»¶mtime

    6. ç¼“å­˜å¤±æ•ˆ:
       â””â”€ æ¸…é™¤ç›¸ä¼¼åº¦è®¡ç®—ç¼“å­˜
    """
```

**æ–‡ä»¶å¤„ç†ä¼˜å…ˆçº§**:
```python
# ç­–ç•¥: ç¬¦å·æ˜ å°„ -> æ–‡æ¡£ç»“æ„ -> åŸå§‹åå¤‡
if file_path in symbol_map:
    text_to_embed = generate_symbol_essence_string(
        file_path,
        symbol_map[file_path],
        symbol_map=symbol_map
    )
else:
    # æ–‡æ¡£æ–‡ä»¶
    if ext in [".md", ".txt", ".rst"]:
        text_to_embed = preprocess_doc_structure(content)
    else:
        # åŸå§‹åå¤‡
        text_to_embed = f"[FILE: {rel_path}]\n{content[:32000]}"
```

#### 2.5 ç›¸ä¼¼åº¦è®¡ç®—

```python
@cached("similarity_calculation",
        key_func=_get_similarity_cache_key,
        ttl=SIM_CACHE_TTL_SEC)
def calculate_similarity(
    key1_str: str,
    key2_str: str,
    embeddings_dir: str,
    path_to_key_info: Dict[str, KeyInfo],
    project_root: str,
    code_roots: List[str],
    doc_roots: List[str]
) -> float:
    """
    ç›¸ä¼¼åº¦è®¡ç®—æµç¨‹:
    1. éªŒè¯å¯†é’¥å­˜åœ¨
    2. å®šä½.npyæ–‡ä»¶
    3. åŠ è½½å‘é‡
    4. è®¡ç®—ç‚¹ç§¯(å‘é‡å·²å½’ä¸€åŒ–)
    5. Clampåˆ°[0, 1]
    6. ç¼“å­˜ç»“æœ(7å¤©TTL)
    """
```

**ç¼“å­˜ç­–ç•¥**:
```python
SIM_CACHE_MAXSIZE = 100_000      # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
SIM_CACHE_TTL_SEC = 7 * 24 * 60 * 60  # 7å¤©TTL
SIM_CACHE_NEGATIVE_RESULTS = True     # ç¼“å­˜è´Ÿç»“æœ

# ç¼“å­˜é”®ç”Ÿæˆ(ç¡®å®šæ€§)
def _get_similarity_cache_key(key1, key2):
    k1, k2 = sorted((key1, key2))  # æ’åºç¡®ä¿(A,B) == (B,A)
    return f"sim_ses:{k1}:{k2}"
```

### ğŸ”§ é«˜çº§ç‰¹æ€§

#### 1. Flash Attention 2 ä¼˜åŒ– (Qwen3 Reranker)

```python
# CUDAè®¾å¤‡ä¸Šè‡ªåŠ¨å¯ç”¨Flash Attention 2
if device == "cuda":
    RERANKER_MODEL = AutoModelForCausalLM.from_pretrained(
        model_name_or_path,
        dtype=torch.float16,  # FP16æå‡æ€§èƒ½
        attn_implementation="flash_attention_2",  # Flash Attention 2
        trust_remote_code=True
    )

# éªŒè¯Flash Attentionå¯ç”¨
if hasattr(RERANKER_MODEL.config, "_attn_implementation"):
    attn_impl = RERANKER_MODEL.config._attn_implementation
    if attn_impl == "flash_attention_2":
        logger.info("Flash Attention 2 is active!")
```

**æ€§èƒ½æå‡**:
- å†…å­˜ä½¿ç”¨å‡å°‘ ~40%
- æ¨ç†é€Ÿåº¦æå‡ ~2-3x
- æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡

#### 2. æ¨¡å‹è‡ªåŠ¨ä¸‹è½½ä¸éªŒè¯

```python
def _download_qwen3_model(model_path: str) -> bool:
    """
    ä¸‹è½½æµç¨‹:
    1. æ£€æŸ¥ç°æœ‰æ¨¡å‹
    2. éªŒè¯å®Œæ•´æ€§(GGUF header + load test)
    3. å¦‚æœæ— æ•ˆ,åˆ é™¤å¹¶é‡æ–°ä¸‹è½½
    4. ä½¿ç”¨PhaseTrackeræ˜¾ç¤ºè¿›åº¦
    5. æœ€ç»ˆéªŒè¯
    """
    # éªŒè¯GGUFæ–‡ä»¶
    with open(model_path, "rb") as f:
        header = f.read(4)
        if header != b"GGUF":
            return False

    # Load test
    test_model = Llama(
        model_path=model_path,
        embedding=True,
        n_ctx=16384,
        verbose=False
    )
```

#### 3. ä¸Šä¸‹æ–‡çª—å£åŠ¨æ€è°ƒæ•´

```python
def _load_model(n_ctx: int = 8192):
    """
    åŠ¨æ€è°ƒæ•´ç­–ç•¥:
    1. å¦‚æœæ¨¡å‹å·²åŠ è½½:
       - æ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡çª—å£
       - å¦‚æœä¸è¶³,å¸è½½å¹¶é‡æ–°åŠ è½½
       - å¦‚æœè¶³å¤Ÿ,å¤ç”¨
    2. å¦‚æœæ˜¯SentenceTransformer:
       - ç›´æ¥æ›´æ–°max_seq_length
       - æ— éœ€é‡æ–°åŠ è½½
    """
    if MODEL_INSTANCE is not None:
        if SELECTED_MODEL_CONFIG["type"] == "gguf":
            current_n_ctx = MODEL_INSTANCE.n_ctx()
            if current_n_ctx < n_ctx:
                _unload_model()
                # é‡æ–°åŠ è½½
```

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡

#### Qwen3-4Bæ¨¡å‹ (Q6_Ké‡åŒ–)

**å†…å­˜å ç”¨** (RTX 4060 8GB):
```
æ¨¡å‹æœ¬ä½“: ~1.1GB
ä¸Šä¸‹æ–‡=1000: +0.3GB
ä¸Šä¸‹æ–‡=4000: +0.5GB
ä¸Šä¸‹æ–‡=8000: +0.8GB
ä¸Šä¸‹æ–‡=16000: +1.5GB
ä¸Šä¸‹æ–‡=32000: +2.5GB
```

**æ¨ç†é€Ÿåº¦** (æ‰¹æ¬¡å¤§å°è‡ªé€‚åº”):
```
ä¸Šä¸‹æ–‡=1000: ~15æ ·æœ¬/æ‰¹æ¬¡, ~50æ ·æœ¬/ç§’
ä¸Šä¸‹æ–‡=4000: ~8æ ·æœ¬/æ‰¹æ¬¡, ~25æ ·æœ¬/ç§’
ä¸Šä¸‹æ–‡=8000: ~5æ ·æœ¬/æ‰¹æ¬¡, ~15æ ·æœ¬/ç§’
ä¸Šä¸‹æ–‡=16000: ~3æ ·æœ¬/æ‰¹æ¬¡, ~8æ ·æœ¬/ç§’
ä¸Šä¸‹æ–‡=32000: ~2æ ·æœ¬/æ‰¹æ¬¡, ~5æ ·æœ¬/ç§’
```

#### all-mpnet-base-v2æ¨¡å‹

**å†…å­˜å ç”¨**:
```
æ¨¡å‹æœ¬ä½“: ~400MB
æ‰¹æ¬¡å¤§å°=32: +100MB
æ‰¹æ¬¡å¤§å°=64: +200MB
```

**æ¨ç†é€Ÿåº¦**:
```
CPU: ~100æ ·æœ¬/ç§’
CUDA: ~500æ ·æœ¬/ç§’
```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **GGUFæ¨¡å‹æ—¥å¿—æŠ‘åˆ¶**:
```python
# ä½¿ç”¨no-op callbackæŠ‘åˆ¶C++åº“è¾“å‡º
import ctypes
LogCallback = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_char_p, ctypes.c_void_p)

def noop_log_callback(level, text, user_data):
    pass

_C_LOG_CALLBACK_REF = LogCallback(noop_log_callback)
llama_cpp.llama_log_set(_C_LOG_CALLBACK_REF, ctypes.c_void_p())
```

2. **å†…å­˜æ¸…ç†**:
```python
# åŠæ—¶åˆ é™¤å¼ é‡å’Œæ¸…ç©ºç¼“å­˜
del padded_batch
del logits
if device == "cuda":
    torch.cuda.empty_cache()
```

3. **Rerankerå¸è½½**:
```python
# åˆ†æå®Œæˆåå¸è½½rerankeré‡Šæ”¾VRAM
try:
    embedding_manager.unload_reranker_model()
except Exception as e:
    logger.warning(f"Error during reranker unload: {e}")
```

---

## 3. dependency_analyzer.py - ä¾èµ–åˆ†æå™¨

### ğŸ“– æ¨¡å—è¯´æ˜

**æ–‡ä»¶**: `cline_utils/dependency_system/analysis/dependency_analyzer.py`
**è¡Œæ•°**: ~2,160 è¡Œ
**æ ¸å¿ƒåŠŸèƒ½**: è§£ææºä»£ç æ–‡ä»¶,æå–ä¾èµ–å…³ç³»å’Œç¬¦å·ä¿¡æ¯

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

#### 3.1 å¤šè¯­è¨€åˆ†ææ”¯æŒ

| è¯­è¨€ | åˆ†ææ–¹æ³• | æå–ä¿¡æ¯ |
|------|---------|---------|
| **Python** | AST + Tree-sitter | imports, functions, classes, calls, attributes, inheritance, type_refs, decorators, exceptions, with_contexts |
| **JavaScript** | Tree-sitter | imports, exports, functions, classes, calls |
| **TypeScript** | Tree-sitter | imports, exports, functions, classes, calls, type_refs |
| **TSX** | Tree-sitter | imports, exports, functions, classes, calls, type_refs, JSX elements |
| **HTML** | Tree-sitter | links (<a>), scripts (<script>), stylesheets (<link>), images (<img>) |
| **CSS** | Tree-sitter | @import statements |
| **Markdown** | Regex | links [text](url), code blocks ```lang``` |

#### 3.2 ä¸»å‡½æ•°: `analyze_file()`

**å‡½æ•°ç­¾å**:
```python
@cached("file_analysis",
    key_func=lambda file_path, force=False:
        f"analyze_file:{normalize_path(file_path)}:"
        f"{os.path.getmtime(file_path)}:{force}"
)
def analyze_file(file_path: str, force: bool = False) -> Dict[str, Any]:
```

**å®Œæ•´æµç¨‹**:
```
1. é¢„æ£€æŸ¥
   â”œâ”€ éªŒè¯æ–‡ä»¶å­˜åœ¨
   â”œâ”€ æ£€æŸ¥æ’é™¤åˆ—è¡¨
   â””â”€ äºŒè¿›åˆ¶æ–‡ä»¶æ£€æµ‹

2. è¯»å–æ–‡ä»¶å†…å®¹
   â””â”€ UTF-8ç¼–ç ,é”™è¯¯å¤„ç†

3. æ ¹æ®æ–‡ä»¶ç±»å‹åˆ†å‘
   â”œâ”€ .py -> _analyze_python_file() + _analyze_python_file_ts()
   â”œâ”€ .js -> _analyze_javascript_file_ts()
   â”œâ”€ .ts -> _analyze_typescript_file_ts()
   â”œâ”€ .tsx -> _analyze_tsx_file_ts()
   â”œâ”€ .md -> _analyze_markdown_file()
   â”œâ”€ .html -> _analyze_html_file_ts()
   â””â”€ .css -> _analyze_css_file_ts()

4. åˆå¹¶åˆ†æç»“æœ
   â””â”€ _merge_analysis_results() (ASTä¼˜å…ˆ)

5. æ•´åˆä¸å»é‡
   â””â”€ _consolidate_list_of_dicts()

6. ç”Ÿæˆæ‘˜è¦
   â””â”€ symbol_summary, ast_verified_links

7. ç¼“å­˜æ ‘å¯¹è±¡
   â”œâ”€ AST -> "ast_cache"
   â””â”€ Tree-sitter -> "ts_ast_cache"
```

#### 3.3 Pythonæ–‡ä»¶åˆ†æ

##### ASTåˆ†æ (`_analyze_python_file`)

**ä¸¤éæ‰«æç­–ç•¥**:

```python
# ç¬¬ä¸€é: éå†tree.body (é¡¶çº§å®šä¹‰)
for node in tree.body:
    if isinstance(node, ast.Import):
        # å¤„ç†importè¯­å¥
    elif isinstance(node, ast.ImportFrom):
        # å¤„ç†from...importè¯­å¥
    elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
        # æ”¶é›†é¡¶çº§å‡½æ•°
    elif isinstance(node, ast.ClassDef):
        # æ”¶é›†é¡¶çº§ç±»
    elif isinstance(node, (ast.Assign, ast.AnnAssign)):
        # æ”¶é›†å…¨å±€å˜é‡å®šä¹‰

# ç¬¬äºŒé: ast.walk (æ‰€æœ‰èŠ‚ç‚¹,åŒ…æ‹¬åµŒå¥—)
for node in ast.walk(tree):
    # å¤„ç†è£…é¥°å™¨ã€ç±»å‹å¼•ç”¨ã€è°ƒç”¨ã€å±æ€§è®¿é—®ç­‰
```

**æå–çš„ä¿¡æ¯**:

1. **Importè¯­å¥**:
```python
# import module
{"name": "module"}

# from package import item as alias
{"name": "item", "from": "package", "alias": "alias"}
```

2. **å‡½æ•°å®šä¹‰**:
```python
{
    "name": "function_name",
    "line": 42,
    "params": ["arg1", "arg2", "*args", "**kwargs"],
    "docstring": "First line of docstring",
    "async": True  # å¦‚æœæ˜¯async def
}
```

3. **ç±»å®šä¹‰**:
```python
{
    "name": "ClassName",
    "line": 10,
    "docstring": "Class documentation",
    "methods": [
        {
            "name": "method_name",
            "line": 15,
            "params": ["self", "param1"],
            "docstring": "Method documentation"
        }
    ]
}
```

4. **ç»§æ‰¿å…³ç³»**:
```python
{
    "class_name": "DerivedClass",
    "base_class_name": "BaseClass",
    "potential_source": "BaseClass",  # å®Œæ•´åç§°(å¯èƒ½åŒ…å«æ¨¡å—)
    "line": 20
}
```

5. **ç±»å‹å¼•ç”¨**:
```python
{
    "type_name_str": "List",
    "context": "arg_annotation",  # æˆ– return_annotation, variable_annotationç­‰
    "target_name": "my_list",
    "line": 25
}
```

6. **å‡½æ•°è°ƒç”¨**:
```python
{
    "target_name": "function_name",  # æˆ– "obj.method_name"
    "potential_source": "obj",  # è°ƒç”¨æ¥æºå¯¹è±¡
    "line": 30
}
```

7. **è£…é¥°å™¨ä½¿ç”¨**:
```python
{
    "name": "decorator_name",
    "target_type": "function",  # æˆ– class, method
    "target_name": "decorated_function",
    "line": 12
}
```

8. **å¼‚å¸¸å¤„ç†**:
```python
{
    "type_name_str": "ValueError",
    "line": 50
}
```

9. **withä¸Šä¸‹æ–‡**:
```python
{
    "context_expr_str": "open('file.txt')",
    "line": 60
}
```

##### Tree-sitterå¢å¼º (`_analyze_python_file_ts`)

**æŸ¥è¯¢æ¨¡å¼**:
```python
# Imports
imports_query_str = """
[
    (import_statement
        name: (dotted_name) @import_name)
    (import_from_statement
        module_name: (dotted_name) @module_name)
]
"""

# Functions
functions_query_str = """
(function_definition
    name: (identifier) @func_name) @function
"""

# Classes
classes_query_str = """
(class_definition
    name: (identifier) @class_name) @class
"""

# Calls
calls_query_str = """
[
  (call
      function: (identifier) @call_func
  )
  (call
      function: (attribute
          object: (_) @call_obj
          attribute: (identifier) @call_attr
      )
  )
]
"""
```

**åˆå¹¶ç­–ç•¥**:
```python
def _merge_analysis_results(primary, secondary):
    """
    åˆå¹¶è§„åˆ™:
    1. ASTç»“æœä¼˜å…ˆ(primary)
    2. Tree-sitterè¡¥å……(secondary)
    3. åŸºäºname+lineå»é‡
    4. å¯¹äºimports/calls,åŸºäºpath/target_nameå»é‡
    """
```

#### 3.4 JavaScript/TypeScriptæ–‡ä»¶åˆ†æ

##### JavaScriptåˆ†æ (`_analyze_javascript_file_ts`)

**æŸ¥è¯¢æ¨¡å¼**:
```python
# Imports (ESMå’Œrequire)
imports_query = """
[
  (import_statement source: (string) @path)
  (call_expression
    function: (identifier) @req.fn
    arguments: (arguments (string) @path)
  ) @require
    (#match? @req.fn "^(require|import)$")
]
"""

# Exports
exports_query = """
[
  (export_statement
      (export_clause (export_specifier name: (identifier) @export.name))
  )
  (export_statement
      (export_clause (export_specifier
          name: (identifier) @export.orig
          alias: (identifier) @export.alias))
  )
  (export_statement
      declaration: (variable_declaration
      (variable_declarator
          name: (identifier) @export.default))
  ) @default.export
  (export_statement
      declaration: (function_declaration name: (identifier) @export.func.name)
  )
  (export_statement
      declaration: (class_declaration name: (identifier) @export.class.name)
  )
]
"""
```

**å¯¼å‡ºä¿¡æ¯æå–**:
```python
# export const x = 1
{"name": "x", "line": 10}

# export { x as y }
{"name": "x", "alias": "y", "line": 15}

# export default MyComponent
{"name": "default", "alias": "MyComponent", "line": 20}

# export { x } from './module'
{"from": "./module", "line": 25}
```

##### TypeScript/TSXåˆ†æ

**é¢å¤–ç±»å‹å¼•ç”¨æå–**:
```python
# Type annotations
type_ann_query = "(type_annotation (type_identifier) @type.name)"

# Generic types
generic_type_query = "(generic_type (type_identifier) @type.name)"

# ç¤ºä¾‹:
# let x: MyType<T> = ...
# ->
# {"type_name_str": "MyType", "context": "type_annotation", "line": 30}
# {"type_name_str": "T", "context": "generic_type", "line": 30}
```

#### 3.5 HTMLæ–‡ä»¶åˆ†æ (`_analyze_html_file_ts`)

**æå–çš„é“¾æ¥ç±»å‹**:

```python
# <script src="path/to/script.js">
scripts: [{"url": "path/to/script.js", "line": 10}]

# <link href="styles.css" rel="stylesheet">
stylesheets: [{"url": "styles.css", "line": 15}]

# <img src="image.png">
images: [{"url": "image.png", "line": 20}]

# <a href="page.html">
links: [{"url": "page.html", "line": 25}]
```

**Tree-sitteræŸ¥è¯¢**:
```python
queries = {
    "scripts": '(script_element (start_tag (attribute (attribute_name) @name (#eq? @name "src") (quoted_attribute_value (attribute_value) @path))))',
    "stylesheets": '(element (start_tag (tag_name) @tag (#eq? @tag "link") (attribute (attribute_name) @name (#eq? @name "href") (quoted_attribute_value (attribute_value) @path))))',
    "images": '(element (start_tag (tag_name) @tag (#eq? @tag "img") (attribute (attribute_name) @name (#eq? @name "src") (quoted_attribute_value (attribute_value) @path))))',
    "links": '(element (start_tag (tag_name) @tag (#eq? @tag "a") (attribute (attribute_name) @name (#eq? @name "href") (quoted_attribute_value (attribute_value) @path))))',
}
```

#### 3.6 CSSæ–‡ä»¶åˆ†æ (`_analyze_css_file_ts`)

**@importæå–**:
```python
# @import "styles.css";
# @import url("styles.css");
imports: [{"url": "styles.css", "line": 5}]

# Tree-sitteræŸ¥è¯¢
query_str = """
(import_statement (string_value) @path)
"""
```

#### 3.7 Markdownæ–‡ä»¶åˆ†æ (`_analyze_markdown_file`)

**æ­£åˆ™è¡¨è¾¾å¼æå–**:

```python
# [é“¾æ¥æ–‡æœ¬](url)
MARKDOWN_LINK_PATTERN = re.compile(r"\[(?:[^\]]+)\]\(([^)]+)\)")
links: [{"url": "path/to/file.md", "line": 10}]

# ```language
# code
# ```
code_block_pattern = re.compile(r"```(\w+)?\n(.*?)```", re.DOTALL)
code_blocks: [
    {
        "language": "python",
        "line": 15,
        "content": "def example():\n    pass"
    }
]
```

### ğŸ”§ é«˜çº§ç‰¹æ€§

#### 1. è°ƒç”¨è¿‡æ»¤ (`_is_useful_call`)

**è¿‡æ»¤ç­–ç•¥**:
```python
def _is_useful_call(target_name, potential_source, imports_map):
    """
    è¿‡æ»¤é€»è¾‘:
    1. æ‰‹åŠ¨é»‘åå•æ£€æŸ¥ (logger, consoleç­‰)
    2. è·¯å¾„è§£æè¿‡æ»¤:
       - å¦‚æœæ˜¯å¯¼å…¥çš„æ¨¡å—,æ£€æŸ¥æ˜¯å¦ä¸ºå†…éƒ¨æ¨¡å—
       - å¦‚æœæ˜¯å¤–éƒ¨åº“,è¿‡æ»¤æ‰
    3. é€šç”¨æ–¹æ³•åè¿‡æ»¤ (get, set, appendç­‰)
    4. å†…ç½®ç±»å‹æ–¹æ³•è¿‡æ»¤ (str.splitç­‰)
    """
```

**é»‘åå•**:
```python
# å¿½ç•¥çš„è°ƒç”¨æº
IGNORED_CALL_SOURCES = {
    "logger", "logging", "os", "sys", "json", "re",
    "math", "datetime", "time", "random", "subprocess",
    "shutil", "pathlib", "typing", "argparse", ...
}

# é€šç”¨è°ƒç”¨å
GENERIC_CALL_NAMES = {
    "get", "set", "update", "append", "extend", "pop",
    "remove", "clear", "copy", "keys", "values", "items",
    "split", "join", "strip", "replace", "format", ...
}
```

#### 2. å†…éƒ¨æ¨¡å—è¯†åˆ« (`_is_internal_module`)

```python
@cached("is_internal_module",
        key_func=lambda module_name: f"is_internal:{module_name}")
def _is_internal_module(module_name: str) -> bool:
    """
    æ£€æŸ¥é€»è¾‘:
    1. æ£€æŸ¥æ˜¯å¦ä¸ºå†…ç½®æ¨¡å— -> False
    2. è·å–é¡¶çº§åŒ…å (psycopg.sql -> psycopg)
    3. éå†ä»£ç æ ¹ç›®å½•:
       - æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒåç›®å½•(åŒ…)
       - æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒå.pyæ–‡ä»¶(æ¨¡å—)
    4. å­˜åœ¨ -> True, å¦åˆ™ -> False
    """
```

#### 3. åˆå¹¶ä¸å»é‡ (`_consolidate_list_of_dicts`)

```python
def _consolidate_list_of_dicts(items, group_by_keys):
    """
    åˆå¹¶ç­–ç•¥:
    1. æŒ‰æŒ‡å®šé”®åˆ†ç»„ (name, target_nameç­‰)
    2. åˆå¹¶lineå­—æ®µä¸ºåˆ—è¡¨
    3. ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„å…¶ä»–å­—æ®µ
    4. å¯¹lineåˆ—è¡¨å»é‡å¹¶æ’åº

    ç¤ºä¾‹:
    [
        {"name": "func", "line": 10, "params": ["x"]},
        {"name": "func", "line": 15, "params": ["x"]}
    ]
    ->
    [{"name": "func", "line": [10, 15], "params": ["x"]}]
    """
```

**å„å­—æ®µçš„åˆå¹¶é”®**:
```python
consolidation_map = {
    "calls": ["target_name", "potential_source"],
    "functions": ["name"],
    "classes": ["name"],
    "globals_defined": ["name"],
    "attribute_accesses": ["target_name", "potential_source"],
    "inheritance": ["class_name", "base_class_name"],
    "type_references": ["type_name_str", "context", "target_name"],
    "decorators_used": ["name", "target_type", "target_name"],
    "exceptions_handled": ["type_name_str"],
    "with_contexts_used": ["context_expr_str"],
    "code_blocks": ["language", "content"],
    "links": ["url"],
    "scripts": ["url"],
    "stylesheets": ["url"],
    "images": ["url"],
}
```

#### 4. äºŒè¿›åˆ¶æ–‡ä»¶æ£€æµ‹

```python
# å¯å‘å¼æ£€æµ‹: æ£€æŸ¥å‰1024å­—èŠ‚æ˜¯å¦åŒ…å«nullå­—èŠ‚
with open(file_path, "rb") as f:
    if b"\0" in f.read(1024):
        return {"skipped": True, "reason": "Binary file detected"}
```

#### 5. Tree-sitterçº¿ç¨‹å®‰å…¨

**é‡è¦ä¿®å¤**:
```python
# é”™è¯¯åšæ³•(å…¨å±€Parser,éçº¿ç¨‹å®‰å…¨):
# JS_PARSER = Parser(JS_LANGUAGE)  # æ¨¡å—çº§å…¨å±€

# æ­£ç¡®åšæ³•(å±€éƒ¨Parser,çº¿ç¨‹å®‰å…¨):
def _analyze_javascript_file_ts(...):
    parser = Parser(JS_LANGUAGE)  # æ¯æ¬¡è°ƒç”¨åˆ›å»ºæ–°å®ä¾‹
    tree = parser.parse(content_bytes)
```

### ğŸ“Š è¿”å›æ•°æ®ç»“æ„

**å®Œæ•´åˆ†æç»“æœ**:
```python
{
    "file_path": str,              # è§„èŒƒåŒ–ç»å¯¹è·¯å¾„
    "file_type": str,              # py/js/ts/tsx/html/css/md
    "size": int,                   # æ–‡ä»¶å¤§å°(å­—èŠ‚)

    # é€šç”¨å­—æ®µ
    "imports": List[Dict],         # å¯¼å…¥è¯­å¥
    "exports": List[Dict],         # å¯¼å‡ºè¯­å¥(JS/TS)
    "links": List[Dict],           # é“¾æ¥(HTML/MD)
    "functions": List[Dict],       # å‡½æ•°å®šä¹‰
    "classes": List[Dict],         # ç±»å®šä¹‰
    "calls": List[Dict],           # å‡½æ•°è°ƒç”¨

    # Pythonç‰¹æœ‰
    "attribute_accesses": List[Dict],  # å±æ€§è®¿é—®
    "inheritance": List[Dict],         # ç»§æ‰¿å…³ç³»
    "type_references": List[Dict],     # ç±»å‹å¼•ç”¨
    "globals_defined": List[Dict],     # å…¨å±€å˜é‡å®šä¹‰
    "decorators_used": List[Dict],     # è£…é¥°å™¨ä½¿ç”¨
    "exceptions_handled": List[Dict],  # å¼‚å¸¸å¤„ç†
    "with_contexts_used": List[Dict],  # withä¸Šä¸‹æ–‡

    # HTMLç‰¹æœ‰
    "scripts": List[Dict],         # <script>æ ‡ç­¾
    "stylesheets": List[Dict],     # <link>æ ·å¼è¡¨
    "images": List[Dict],          # <img>å›¾ç‰‡

    # Markdownç‰¹æœ‰
    "code_blocks": List[Dict],     # ä»£ç å—

    # å†…éƒ¨ä½¿ç”¨(ä¸å¯¼å‡º)
    "_ast_tree": Optional[ast.AST],      # Python ASTæ ‘(ç¼“å­˜åˆ°ast_cache)
    "_ts_tree": Optional[Tree],          # Tree-sitteræ ‘(ç¼“å­˜åˆ°ts_ast_cache)

    # æ‘˜è¦
    "symbol_summary": Dict,        # è·¨è¯­è¨€æ ‡å‡†åŒ–æ‘˜è¦
    "ast_verified_links": List[Dict],  # ASTéªŒè¯çš„é“¾æ¥

    # é”™è¯¯/è·³è¿‡
    "error": Optional[str],        # é”™è¯¯ä¿¡æ¯
    "skipped": Optional[bool],     # æ˜¯å¦è·³è¿‡
    "reason": Optional[str],       # è·³è¿‡åŸå› 
}
```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **ASTæ ‘ç¼“å­˜ç®¡ç†**:
```python
# åˆ†æå®Œæˆå,ASTæ ‘è¢«ç¼“å­˜åˆ°å•ç‹¬çš„"ast_cache"
# ä¸å†åŒ…å«åœ¨analysis_resultä¸­,é¿å…åºåˆ—åŒ–é—®é¢˜
ast_cache = cache_manager.get_cache("ast_cache")
ast_cache.set(norm_file_path, ast_object)
```

2. **ç¼–ç é”™è¯¯å¤„ç†**:
```python
# UTF-8è§£ç å¤±è´¥æ—¶ä¼˜é›…é™çº§
try:
    content = f.read()
except UnicodeDecodeError as e:
    return {
        "error": "Encoding error",
        "details": str(e),
        "file_path": norm_file_path
    }
```

3. **ç¬¦å·å†²çªè§£å†³**:
```python
# Python: åŒåå‡½æ•°/ç±»åœ¨ä¸åŒè¡Œ
# ä½¿ç”¨ name+line ä½œä¸ºå”¯ä¸€æ ‡è¯†
unique_key = f"{item['name']}:{line}"
```

---

## 4. dependency_suggester.py - ä¾èµ–å»ºè®®å™¨

### ğŸ“– æ¨¡å—è¯´æ˜

**æ–‡ä»¶**: `cline_utils/dependency_system/analysis/dependency_suggester.py`
**è¡Œæ•°**: ~2,000+ è¡Œ
**æ ¸å¿ƒåŠŸèƒ½**: åŸºäºæ–‡ä»¶åˆ†æç»“æœå’ŒåµŒå…¥å‘é‡,å»ºè®®æ½œåœ¨çš„ä¾èµ–å…³ç³»

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

#### 4.1 ä¾èµ–å­—ç¬¦ç³»ç»Ÿ

**å­—ç¬¦å®šä¹‰**:
```
< : Row depends on column (è¡Œä¾èµ–åˆ—)
> : Column depends on row (åˆ—ä¾èµ–è¡Œ)
x : Mutual dependency (ç›¸äº’ä¾èµ–)
d : Documentation dependency (æ–‡æ¡£ä¾èµ–)
o : Self dependency (è‡ªæˆ‘ä¾èµ–,ä»…å¯¹è§’çº¿)
n : Verified no dependency (éªŒè¯æ— ä¾èµ–)
p : Placeholder (å ä½ç¬¦,æœªéªŒè¯)
s : Semantic dependency (weak, .06-.07) (å¼±è¯­ä¹‰ä¾èµ–)
S : Semantic dependency (strong, .07+) (å¼ºè¯­ä¹‰ä¾èµ–)
```

**å­—ç¬¦ä¼˜å…ˆçº§** (ä»é«˜åˆ°ä½):
```
1. < (ç»“æ„åŒ–ä¾èµ– - æœ€é«˜ä¼˜å…ˆçº§)
2. > (åå‘ç»“æ„åŒ–ä¾èµ–)
3. x (ç›¸äº’ä¾èµ–)
4. d (æ–‡æ¡£ä¾èµ–)
5. S (å¼ºè¯­ä¹‰ä¾èµ–)
6. s (å¼±è¯­ä¹‰ä¾èµ–)
7. p (å ä½ç¬¦ - æœ€ä½ä¼˜å…ˆçº§)
```

#### 4.2 ä¸»å‡½æ•°: `suggest_dependencies()`

**å‡½æ•°ç­¾å**:
```python
def suggest_dependencies(
    file_path: str,
    path_to_key_info: Dict[str, KeyInfo],
    project_root: str,
    file_analysis_results: Dict[str, Any],
    threshold: float = 0.7,
    shared_scan_counter: Any = None
) -> Tuple[List[Tuple[str, str]], List[Dict[str, str]]]:
```

**è¿”å›å€¼**:
```python
(
    [
        (target_path, char),  # è·¯å¾„åŸºç¡€çš„ä¾èµ–å»ºè®®
        ...
    ],
    [
        {  # ASTéªŒè¯çš„é“¾æ¥
            "source_path": str,
            "target_path": str,
            "char": str,
            "reason": str
        },
        ...
    ]
)
```

**æ–‡ä»¶ç±»å‹åˆ†å‘**:
```python
if file_ext == ".py":
    char_suggestions, py_ast_links = suggest_python_dependencies(...)
elif file_ext in (".js", ".ts", ".tsx", ".mjs", ".cjs"):
    char_suggestions, js_ast_links = suggest_javascript_dependencies(...)
elif file_ext in (".md", ".rst"):
    char_suggestions = suggest_documentation_dependencies(...)
elif file_ext in (".html", ".htm"):
    char_suggestions = suggest_html_dependencies(...)
elif file_ext == ".css":
    char_suggestions = suggest_css_dependencies(...)
else:
    char_suggestions = suggest_generic_dependencies(...)
```

#### 4.3 Pythonä¾èµ–å»ºè®®

##### ç»“æ„åŒ–ä¾èµ–è¯†åˆ« (`_identify_structural_dependencies`)

**å¤„ç†æµç¨‹**:
```
1. æ„å»ºå¯¼å…¥æ˜ å°„
   â”œâ”€ è§£æimportè¯­å¥
   â”œâ”€ ä½¿ç”¨ASTæ ‘(ä»ast_cacheè·å–)
   â””â”€ æ˜ å°„: local_name -> absolute_module_path

2. å¤„ç†å„ç±»ä¾èµ–æº
   â”œâ”€ å‡½æ•°è°ƒç”¨ (calls)
   â”œâ”€ å±æ€§è®¿é—® (attribute_accesses)
   â”œâ”€ ç»§æ‰¿å…³ç³» (inheritance)
   â”œâ”€ ç±»å‹å¼•ç”¨ (type_references)
   â”œâ”€ è£…é¥°å™¨ä½¿ç”¨ (decorators_used)
   â”œâ”€ å¼‚å¸¸å¤„ç† (exceptions_handled)
   â””â”€ withä¸Šä¸‹æ–‡ (with_contexts_used)

3. ç¬¦å·è§£æ
   â”œâ”€ æŸ¥æ‰¾ç¬¦å·å®šä¹‰ä½ç½®
   â”œâ”€ ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ç¬¦å·æ˜ å°„
   â””â”€ å›é€€åˆ°è·¯å¾„è§£æ

4. ç”Ÿæˆå»ºè®®
   â”œâ”€ åˆ†é…å­—ç¬¦(</>)
   â””â”€ åˆ›å»ºASTéªŒè¯é“¾æ¥
```

**å¯¼å…¥æ˜ å°„æ„å»º** (`_build_import_map`):
```python
def _build_import_map(current_source_path, tree):
    """
    ç¤ºä¾‹:
    import my_module.sub
    -> {"my_module.sub": "/abs/path/to/my_module/sub.py"}

    import my_module.sub as s
    -> {"s": "/abs/path/to/my_module/sub.py"}

    from my_package import specific_item
    -> {"specific_item": "/abs/path/to/my_package/__init__.py"}

    from my_package.another_module import specific_item as si
    -> {"si": "/abs/path/to/my_package/another_module.py"}
    """
```

**Pythonå¯¼å…¥è·¯å¾„è½¬æ¢** (`_convert_python_import_to_paths`):
```python
def _convert_python_import_to_paths(
    import_name: str,
    source_file_dir: str,
    project_root: str,
    path_to_key_info: Dict[str, KeyInfo],
    project_symbol_map: Dict[str, Dict[str, Any]],
    specific_item_name: Optional[str] = None,
    relative_level: int = 0
) -> List[Tuple[str, bool]]:
    """
    è½¬æ¢æµç¨‹:
    1. å¤„ç†ç›¸å¯¹å¯¼å…¥ (from . import x)
       - æ ¹æ®relative_levelè®¡ç®—åŸºç¡€ç›®å½•
    2. å¤„ç†ç»å¯¹å¯¼å…¥
       - ä»å„ä¸ªä»£ç æ ¹ç›®å½•æœç´¢
    3. åŒ…/æ¨¡å—è§£æ
       - æ£€æŸ¥__init__.py
       - æ£€æŸ¥.pyæ–‡ä»¶
    4. ç¬¦å·éªŒè¯ (å¦‚æœæŒ‡å®šspecific_item_name)
       - åœ¨ç¬¦å·æ˜ å°„ä¸­æŸ¥æ‰¾
       - æ£€æŸ¥æ˜¯å¦ä¸ºå­æ¨¡å—

    è¿”å›: [(resolved_path, item_verified), ...]
    """
```

**è°ƒç”¨è§£æç¤ºä¾‹**:
```python
# æºæ–‡ä»¶: /project/module_a/file1.py
# ä»£ç : result = utils.process_data(x)

# æ­¥éª¤1: åœ¨å¯¼å…¥æ˜ å°„ä¸­æŸ¥æ‰¾"utils"
# import_map = {"utils": "/project/module_b/utils.py"}

# æ­¥éª¤2: åœ¨utils.pyçš„ç¬¦å·æ˜ å°„ä¸­æŸ¥æ‰¾"process_data"
# symbol_map["/project/module_b/utils.py"]["functions"]
# = [{"name": "process_data", "line": 42, ...}]

# æ­¥éª¤3: ç”Ÿæˆä¾èµ–å»ºè®®
# ("/project/module_b/utils.py", "<")  # file1ä¾èµ–utils

# æ­¥éª¤4: ç”ŸæˆASTéªŒè¯é“¾æ¥
# {
#     "source_path": "/project/module_a/file1.py",
#     "target_path": "/project/module_b/utils.py",
#     "char": "<",
#     "reason": "call:process_data"
# }
```

##### è¯­ä¹‰ä¾èµ–å»ºè®® (`_suggest_semantic_dependencies_python`)

**æµç¨‹**:
```python
def _suggest_semantic_dependencies_python(...):
    """
    1. åŠ è½½åµŒå…¥å…ƒæ•°æ®
    2. è¿‡æ»¤å€™é€‰æ–‡ä»¶
       - åŒç±»å‹ä¼˜å…ˆ(.py -> .py)
       - æ’é™¤è‡ªèº«
       - æ’é™¤å·²æœ‰ç»“æ„åŒ–ä¾èµ–
    3. è®¡ç®—ç›¸ä¼¼åº¦
       - ä½¿ç”¨calculate_similarity()
       - æ‰¹é‡è®¡ç®—
    4. è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
    5. Reranking (å¯é€‰,å¦‚æœå¯ç”¨)
       - ä½¿ç”¨Qwen3 Reranker
       - å…¨å±€æ‰«æé™åˆ¶(æ€§èƒ½ä¼˜åŒ–)
    6. åˆ†é…å­—ç¬¦
       - >= 0.07: 'S' (å¼ºè¯­ä¹‰)
       - >= 0.06: 's' (å¼±è¯­ä¹‰)
    """
```

**Rerankerä½¿ç”¨**:
```python
# å…¨å±€æ‰«æé™åˆ¶
MAX_RERANKER_SCANS = 100  # æ•´ä¸ªé¡¹ç›®æœ€å¤šé‡æ’åº100æ¬¡

# æ¯ä¸ªæ–‡ä»¶çš„é‡æ’åºé€»è¾‘
if shared_scan_counter is not None:
    with shared_scan_counter.get_lock():
        current_count = shared_scan_counter.value
        if current_count < MAX_RERANKER_SCANS:
            shared_scan_counter.value += 1
            # æ‰§è¡Œreranking
            reranked_results = rerank_candidates_with_qwen3(
                query_text=source_ses,
                candidate_texts=candidate_ses_list,
                top_k=10,
                source_file_path=source_path
            )
```

#### 4.4 JavaScript/TypeScriptä¾èµ–å»ºè®®

##### å¯¼å…¥è§£æ (`suggest_javascript_dependencies`)

**ç‰¹æ®Šå¤„ç†**:
```python
# 1. tsconfig.json / jsconfig.json è§£æ
config_data = _find_and_parse_tsconfig(source_file_dir, project_root)

# 2. è·¯å¾„åˆ«åè§£æ
if config_data and "compilerOptions" in config_data:
    paths = config_data["compilerOptions"].get("paths", {})
    # ç¤ºä¾‹: "@/*" -> "./src/*"

# 3. å¯¼å…¥è·¯å¾„è§£æ
for imp in imports:
    import_path_str = imp.get("path")

    # ç›¸å¯¹è·¯å¾„
    if import_path_str.startswith('.'):
        resolved = _resolve_js_relative_import(...)

    # åˆ«åè·¯å¾„
    elif import_path_str.startswith('@'):
        resolved = _resolve_ts_path_alias(...)

    # åŒ…å¯¼å…¥
    else:
        # æ£€æŸ¥node_modules(é€šå¸¸è·³è¿‡å¤–éƒ¨ä¾èµ–)
        pass
```

**ç¬¦å·éªŒè¯**:
```python
# æ£€æŸ¥å¯¼å…¥çš„ç¬¦å·æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶çš„exportsä¸­
target_exports = symbol_map.get(target_path, {}).get("exports", [])
is_verified = any(
    exp.get("name") == symbol_name
    for exp in target_exports
)
```

#### 4.5 æ–‡æ¡£ä¾èµ–å»ºè®® (`suggest_documentation_dependencies`)

**æµç¨‹**:
```python
def suggest_documentation_dependencies(...):
    """
    1. åŠ è½½åµŒå…¥å…ƒæ•°æ®
    2. è¯†åˆ«æ–‡æ¡£æ–‡ä»¶
       - .md, .rstä¼˜å…ˆ
    3. è¯†åˆ«ä»£ç æ–‡ä»¶
       - .py, .js, .tsç­‰
    4. è®¡ç®—æ–‡æ¡£->ä»£ç ç›¸ä¼¼åº¦
       - ä½¿ç”¨æ–‡æ¡£ç‰¹å®šçš„é¢„å¤„ç†
       - è®¡ç®—å‘é‡ç›¸ä¼¼åº¦
    5. Reranking
       - ä½¿ç”¨æ–‡æ¡£ç‰¹å®šçš„instruction
    6. åˆ†é…'d'å­—ç¬¦
    """
```

**æ–‡æ¡£é¢„å¤„ç†**:
```python
def preprocess_doc_structure(content: str) -> str:
    """
    è¿”å›å®Œæ•´å†…å®¹(æˆªæ–­è‡³32kå­—ç¬¦)ä»¥ä¿ç•™ä¸Šä¸‹æ–‡
    ä¸è¿›è¡Œè¿‡åº¦æ¸…ç†,ä¿ç•™ç»“æ„ä¿¡æ¯
    """
    return content[:32000]
```

#### 4.6 å»ºè®®åˆå¹¶ä¸å»é‡

##### å­—ç¬¦ä¼˜å…ˆçº§åˆå¹¶ (`combine_suggestions_path_based_with_char_priority`)

```python
def combine_suggestions_path_based_with_char_priority(
    path_suggestions: List[Tuple[str, str]],
    source_path: str
) -> List[Tuple[str, str]]:
    """
    åˆå¹¶è§„åˆ™:
    1. æŒ‰target_pathåˆ†ç»„
    2. æ”¶é›†æ‰€æœ‰å­—ç¬¦
    3. åº”ç”¨ä¼˜å…ˆçº§:
       '<' > '>' > 'x' > 'd' > 'S' > 's' > 'p'
    4. é€‰æ‹©æœ€é«˜ä¼˜å…ˆçº§å­—ç¬¦
    5. è‡ªä¾èµ–ç‰¹æ®Šå¤„ç† -> 'o'

    ç¤ºä¾‹:
    [
        ("/path/to/file.py", "<"),  # ç»“æ„åŒ–ä¾èµ–
        ("/path/to/file.py", "s"),  # å¼±è¯­ä¹‰ä¾èµ–
        ("/path/to/file.py", "S"),  # å¼ºè¯­ä¹‰ä¾èµ–
    ]
    ->
    [("/path/to/file.py", "<")]  # ç»“æ„åŒ–ä¼˜å…ˆ
    """
```

**å­—ç¬¦ä¼˜å…ˆçº§æ˜ å°„**:
```python
CHAR_PRIORITY_MAP = {
    '<': 7,  # æœ€é«˜ä¼˜å…ˆçº§
    '>': 6,
    'x': 5,
    'd': 4,
    'S': 3,
    's': 2,
    'p': 1,  # æœ€ä½ä¼˜å…ˆçº§
    'o': 8,  # è‡ªä¾èµ–ç‰¹æ®Šä¼˜å…ˆçº§
    'n': 0,  # éªŒè¯æ— ä¾èµ–
}
```

#### 4.7 TypeScripté…ç½®è§£æ

##### tsconfig.json / jsconfig.json æ”¯æŒ

**æŸ¥æ‰¾ç­–ç•¥**:
```python
@cached("tsconfig_data", ...)
def _find_and_parse_tsconfig(start_dir, project_root):
    """
    å‘ä¸Šéå†ç›®å½•æ ‘æŸ¥æ‰¾é…ç½®æ–‡ä»¶:
    1. ä»start_dirå¼€å§‹
    2. æŸ¥æ‰¾tsconfig.jsonæˆ–jsconfig.json
    3. å¦‚æœæ‰¾åˆ°,è§£æ(æ”¯æŒJSONC)
    4. å‘ä¸Šåˆ°project_root
    5. ç¼“å­˜ç»“æœ
    """
```

**è·¯å¾„åˆ«åè§£æ**:
```python
# tsconfig.json:
{
  "compilerOptions": {
    "baseUrl": "./src",
    "paths": {
      "@/*": ["*"],
      "@components/*": ["components/*"],
      "@utils/*": ["utils/*"]
    }
  }
}

# å¯¼å…¥: import { Button } from '@components/Button'
# è§£æ: ./src/components/Button.ts
```

**è§£æé€»è¾‘**:
```python
def _resolve_ts_path_alias(...):
    for alias_pattern, targets in paths.items():
        if import_spec.startswith(alias_pattern.rstrip('/*')):
            for target_pattern in targets:
                # æ›¿æ¢åˆ«åä¸ºå®é™…è·¯å¾„
                # å°è¯•å„ç§æ‰©å±•å(.ts, .tsx, .jsç­‰)
                # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
```

### ğŸ”§ é«˜çº§ç‰¹æ€§

#### 1. é¡¹ç›®ç¬¦å·æ˜ å°„åŠ è½½

```python
@cached("project_symbol_map_data",
        key_func=lambda: f"project_symbol_map:{mtime}")
def load_project_symbol_map() -> Dict[str, Dict[str, Any]]:
    """
    åŠ è½½project_symbol_map.json:
    1. ç¡®å®šè·¯å¾„(ç›¸å¯¹äºkey_manager.py)
    2. åŠ è½½JSON
    3. ç¼“å­˜(åŸºäºmtime)
    4. è¿”å›æ˜ å°„

    ç»“æ„:
    {
        "/abs/path/to/file.py": {
            "file_type": "py",
            "functions": [...],
            "classes": [...],
            "globals_defined": [...],
            "imports": [...],
            "calls": [...],
            ...
        },
        ...
    }
    """
```

#### 2. ç¬¦å·æŸ¥æ‰¾ä¼˜åŒ–

**å‡½æ•°ç¬¦å·æŸ¥æ‰¾**:
```python
def _find_symbol_in_project(
    symbol_name: str,
    symbol_type: str,  # "function", "class", "global"
    project_symbol_map: Dict[str, Dict[str, Any]],
    hint_paths: Optional[List[str]] = None
) -> List[str]:
    """
    æŸ¥æ‰¾ç­–ç•¥:
    1. å¦‚æœæœ‰hint_paths,ä¼˜å…ˆæœç´¢è¿™äº›æ–‡ä»¶
    2. å¦åˆ™éå†æ•´ä¸ªç¬¦å·æ˜ å°„
    3. åŒ¹é…symbol_nameå’Œsymbol_type
    4. è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„

    ä¼˜åŒ–:
    - ä½¿ç”¨hint_pathsç¼©å°æœç´¢èŒƒå›´
    - æ—©åœ(æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…)
    """
```

#### 3. ç›¸å¯¹å¯¼å…¥å¤„ç†

**Pythonç›¸å¯¹å¯¼å…¥**:
```python
# from .. import module (level=2)
# from . import module (level=1)
# from .subpackage import module (level=1, module_name="subpackage")

# è®¡ç®—åŸºç¡€ç›®å½•
base_dir = current_source_dir
for _ in range(level):
    base_dir = os.path.dirname(base_dir)
    if not base_dir.startswith(project_root):
        # è¶…å‡ºé¡¹ç›®èŒƒå›´,å›é€€åˆ°é¡¹ç›®æ ¹ç›®å½•
        base_dir = project_root
        break
```

**JavaScript/TypeScriptç›¸å¯¹å¯¼å…¥**:
```python
# import { x } from './utils'
# import { y } from '../helpers/utils'

def _resolve_js_relative_import(...):
    # 1. ç»„åˆè·¯å¾„
    raw_path = os.path.join(source_file_dir, import_path)

    # 2. è§„èŒƒåŒ–
    resolved = normalize_path(raw_path)

    # 3. å°è¯•å„ç§æ‰©å±•å
    for ext in ['.ts', '.tsx', '.js', '.jsx', '']:
        candidate = resolved + ext
        if os.path.exists(candidate):
            return candidate

    # 4. å°è¯•indexæ–‡ä»¶
    for ext in ['.ts', '.tsx', '.js', '.jsx']:
        index_file = os.path.join(resolved, f'index{ext}')
        if os.path.exists(index_file):
            return index_file
```

#### 4. ç¼“å­˜ç®¡ç†

**å¤šçº§ç¼“å­˜**:
```python
# æ¨¡å—çº§ç¼“å­˜
_structural_import_map_cache: Dict[str, Dict[str, str]] = {}
_structural_resolved_path_cache: Dict[Tuple[str, Optional[str]], Optional[str]] = {}

# è£…é¥°å™¨ç¼“å­˜
@cached("tsconfig_data", ...)
@cached("project_symbol_map_data", ...)
@cached("is_internal_module", ...)

# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
def clear_caches():
    clear_all_caches()  # è£…é¥°å™¨ç¼“å­˜
    _find_and_parse_tsconfig._cache.clear()
    _structural_import_map_cache.clear()
    _structural_resolved_path_cache.clear()
    load_project_symbol_map._cache.clear()
```

### ğŸ“Š æ€§èƒ½ä¼˜åŒ–

#### 1. å…±äº«æ‰«æè®¡æ•°å™¨

```python
# é˜²æ­¢è¿‡åº¦ä½¿ç”¨Reranker
import multiprocessing
shared_scan_counter = multiprocessing.Value("i", 0)

# å…¨å±€é™åˆ¶
MAX_RERANKER_SCANS = 100

# ä½¿ç”¨
with shared_scan_counter.get_lock():
    current_count = shared_scan_counter.value
    if current_count < MAX_RERANKER_SCANS:
        shared_scan_counter.value += 1
        # æ‰§è¡Œreranking
```

#### 2. æ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®—

```python
# æ”¶é›†æ‰€æœ‰éœ€è¦è®¡ç®—çš„é”®å¯¹
similarity_tasks = [
    (source_key, candidate_key)
    for candidate_key in candidate_keys
]

# å¹¶è¡Œè®¡ç®—
with ThreadPoolExecutor() as executor:
    similarities = list(executor.map(
        lambda pair: calculate_similarity(*pair, ...),
        similarity_tasks
    ))
```

#### 3. ç¬¦å·æ˜ å°„é¢„åŠ è½½

```python
# ä¸€æ¬¡æ€§åŠ è½½,æ‰€æœ‰æ–‡ä»¶å…±äº«
project_symbol_map = load_project_symbol_map()

# ä¼ é€’ç»™æ¯ä¸ªå»ºè®®å‡½æ•°
suggest_python_dependencies(..., project_symbol_map)
suggest_javascript_dependencies(..., project_symbol_map)
```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **ASTæ ‘è·å–**:
```python
# å¿…é¡»ä»ä¸“ç”¨çš„ast_cacheè·å–,ä¸åœ¨analysis_resultä¸­
ast_cache = cache_manager.get_cache("ast_cache")
tree = ast_cache.get(norm_source_path)

if not tree:
    logger.error("AST tree not found in 'ast_cache'")
    return {}  # æ— æ³•æ„å»ºå¯¼å…¥æ˜ å°„
```

2. **è·¯å¾„è§„èŒƒåŒ–**:
```python
# å§‹ç»ˆä½¿ç”¨normalize_pathç¡®ä¿ä¸€è‡´æ€§
norm_path = normalize_path(raw_path)

# è·¯å¾„æ¯”è¾ƒ
if norm_path1 == norm_path2:  # å¯é 
if raw_path1 == raw_path2:    # ä¸å¯é 
```

3. **ç¬¦å·éªŒè¯å®¹é”™**:
```python
# å³ä½¿ç¬¦å·éªŒè¯å¤±è´¥,ä»ç„¶åˆ›å»ºä¾èµ–å»ºè®®
# ä½†æ ‡è®°ä¸ºæœªéªŒè¯
(target_path, '<', False)  # item_verified=False
```

4. **å¤–éƒ¨ä¾èµ–è¿‡æ»¤**:
```python
# è·³è¿‡node_modules, site-packagesç­‰å¤–éƒ¨ä¾èµ–
if 'node_modules' in candidate_path:
    continue
if 'site-packages' in candidate_path:
    continue
```

---

## æ•°æ®æµç¨‹å›¾

### å®Œæ•´åˆ†ææµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   analyze_project()                         â”‚
â”‚                  (project_analyzer.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚               â”‚
       â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Key Generationâ”‚ â”‚File Analysisâ”‚ â”‚Symbol Map   â”‚
â”‚(key_manager) â”‚ â”‚(analyzer)   â”‚ â”‚Generation   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚               â”‚
       â”‚                â”‚               â”‚
       â–¼                â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Path Migration Info                 â”‚
â”‚    (old_key -> new_key mapping)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Embedding Generation                   â”‚
â”‚    (embedding_manager.py)                   â”‚
â”‚                                             â”‚
â”‚  1. Load Symbol Map                         â”‚
â”‚  2. Generate SES                            â”‚
â”‚  3. Select Best Model                       â”‚
â”‚  4. Batch Encode                            â”‚
â”‚  5. Save Vectors (.npy)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Dependency Suggestion (Parallel)         â”‚
â”‚   (dependency_suggester.py)                 â”‚
â”‚                                             â”‚
â”‚  1. Structural Dependencies                 â”‚
â”‚     â”œâ”€ Import Resolution                    â”‚
â”‚     â”œâ”€ Call Analysis                        â”‚
â”‚     â””â”€ Symbol Verification                  â”‚
â”‚                                             â”‚
â”‚  2. Semantic Dependencies                   â”‚
â”‚     â”œâ”€ Vector Similarity                    â”‚
â”‚     â”œâ”€ Reranking (Qwen3)                    â”‚
â”‚     â””â”€ Threshold Filtering                  â”‚
â”‚                                             â”‚
â”‚  3. Character Assignment                    â”‚
â”‚     â””â”€ Priority-based Selection             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           â”‚               â”‚
       â–¼           â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Mini       â”‚ â”‚Doc      â”‚ â”‚Main Tracker  â”‚
â”‚Trackers   â”‚ â”‚Tracker  â”‚ â”‚(Aggregated)  â”‚
â”‚(Module)   â”‚ â”‚(Docs)   â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚            â”‚             â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Visualization                       â”‚
â”‚   (visualize_dependencies.py)               â”‚
â”‚                                             â”‚
â”‚  1. Aggregate Dependencies                  â”‚
â”‚  2. Generate Mermaid Code                   â”‚
â”‚     â”œâ”€ Project Overview                     â”‚
â”‚     â””â”€ Per-Module Diagrams                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµè½¬

```
æºæ–‡ä»¶ (.py, .js, .ts, .html, ...)
    â”‚
    â”œâ”€> [analyze_file] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   (dependency_analyzer.py)       â”‚
    â”‚                                  â”‚
    â”‚   â€¢ AST / Tree-sitter Parsing    â”‚
    â”‚   â€¢ Symbol Extraction            â”‚
    â”‚   â€¢ Dependency Identification    â”‚
    â”‚                                  â”‚
    â–¼                                  â”‚
åˆ†æç»“æœ (analysis_result)              â”‚
    â”œâ”€ imports: List[Dict]             â”‚
    â”œâ”€ functions: List[Dict]           â”‚
    â”œâ”€ classes: List[Dict]             â”‚
    â”œâ”€ calls: List[Dict]               â”‚
    â”œâ”€ type_references: List[Dict]     â”‚
    â””â”€ ...                             â”‚
    â”‚                                  â”‚
    â”œâ”€> [ç¬¦å·æ˜ å°„åˆå¹¶] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   (symbol_map_merger.py)         â”‚
    â”‚                                  â”‚
    â”‚   â€¢ Runtime Symbols (Primary)    â”‚
    â”‚   â€¢ AST Symbols (Enhancement)    â”‚
    â”‚   â€¢ Validation                   â”‚
    â”‚                                  â”‚
    â–¼                                  â”‚
ç¬¦å·æ˜ å°„ (project_symbol_map.json)      â”‚
    {                                  â”‚
      "/path/file.py": {               â”‚
        "file_type": "py",             â”‚
        "functions": [...],            â”‚
        "classes": [...],              â”‚
        ...                            â”‚
      }                                â”‚
    }                                  â”‚
    â”‚                                  â”‚
    â”œâ”€> [generate_embeddings] â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   (embedding_manager.py)         â”‚
    â”‚                                  â”‚
    â”‚   â€¢ Generate SES                 â”‚
    â”‚   â€¢ Encode to Vectors            â”‚
    â”‚   â€¢ Save to .npy                 â”‚
    â”‚                                  â”‚
    â–¼                                  â”‚
åµŒå…¥å‘é‡ (.npy files)                   â”‚
    â”‚                                  â”‚
    â”œâ”€> [suggest_dependencies] â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚   (dependency_suggester.py)
    â”‚
    â”‚   â€¢ Structural Analysis
    â”‚   â€¢ Semantic Similarity
    â”‚   â€¢ Reranking
    â”‚   â€¢ Character Assignment
    â”‚
    â–¼
ä¾èµ–å»ºè®® (suggestions)
    [
      (target_path, char),
      ...
    ]
    â”‚
    â”œâ”€> [è·¯å¾„->å¯†é’¥è½¬æ¢]
    â”‚
    â–¼
KEY#instanceæ ¼å¼å»ºè®®
    {
      "KEY1#1": [
        ("KEY2#1", "<"),
        ("KEY3#1", "S"),
        ...
      ]
    }
    â”‚
    â”œâ”€> [update_tracker]
    â”‚   (tracker_io.py)
    â”‚
    â–¼
è·Ÿè¸ªå™¨æ–‡ä»¶ (.md)
    â€¢ <module>_module.md (Mini)
    â€¢ documentation.md (Doc)
    â€¢ dependencies_main.md (Main)
```

---

## æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨æ‰¹å¤„ç†
```python
# å¥½çš„åšæ³•: æ‰¹é‡å¤„ç†
analysis_results = process_items(
    files_to_analyze,
    analyze_file,
    force=force_analysis
)

# å·®çš„åšæ³•: é¡ºåºå¤„ç†
analysis_results = [
    analyze_file(f) for f in files_to_analyze
]
```

#### å¯ç”¨ç¼“å­˜
```python
# å¥½çš„åšæ³•: åˆ©ç”¨ç¼“å­˜
result = analyze_file(file_path)  # è‡ªåŠ¨ç¼“å­˜

# å·®çš„åšæ³•: æ€»æ˜¯å¼ºåˆ¶é‡æ–°åˆ†æ
result = analyze_file(file_path, force=True)
```

#### å…±äº«é¢„è®¡ç®—ç»“æœ
```python
# å¥½çš„åšæ³•: é¢„èšåˆ,æ‰€æœ‰å›¾å…±äº«
aggregated = aggregate_all_dependencies(...)
for module in modules:
    generate_mermaid_diagram(..., pre_aggregated_links=aggregated)

# å·®çš„åšæ³•: æ¯æ¬¡é‡æ–°èšåˆ
for module in modules:
    # å†…éƒ¨é‡å¤èšåˆ,æµªè´¹
    generate_mermaid_diagram(...)
```

### 2. å†…å­˜ç®¡ç†

#### åŠæ—¶æ¸…ç†ç¼“å­˜
```python
# åˆ†æç»“æŸåæ¸…ç†ASTç¼“å­˜
ast_cache = cache_manager.get_cache("ast_cache")
ast_cache.data.clear()

# å¦‚æœforce_analysis,æ¸…é™¤æ‰€æœ‰ç¼“å­˜
if force_analysis:
    clear_all_caches()
```

#### å¸è½½å¤§æ¨¡å‹
```python
# åˆ†æå®Œæˆåå¸è½½Reranker
try:
    embedding_manager.unload_reranker_model()
except Exception as e:
    logger.warning(f"Reranker unload error: {e}")
```

### 3. é”™è¯¯å¤„ç†

#### åˆ†çº§é”™è¯¯å¤„ç†
```python
try:
    # å…³é”®æ“ä½œ
    result = critical_operation()
except SpecificError as e:
    # ç‰¹å®šé”™è¯¯,è®°å½•è¯¦ç»†ä¿¡æ¯
    logger.error(f"Specific error: {e}")
    return {"error": str(e)}
except Exception as e:
    # é€šç”¨é”™è¯¯,è®°å½•å †æ ˆè·Ÿè¸ª
    logger.exception(f"Unexpected error: {e}")
    return {"error": "Unexpected error"}
```

#### éƒ¨åˆ†å¤±è´¥å®¹å¿
```python
# æ”¶é›†é”™è¯¯,ä¸ä¸­æ–­æµç¨‹
errors = []
for item in items:
    try:
        process(item)
    except Exception as e:
        errors.append((item, str(e)))
        # ç»§ç»­å¤„ç†å…¶ä»–é¡¹

# æœ€åæŠ¥å‘Šæ‰€æœ‰é”™è¯¯
if errors:
    logger.warning(f"Partial failures: {len(errors)}")
```

### 4. é…ç½®ç®¡ç†

#### ä½¿ç”¨é…ç½®é˜ˆå€¼
```python
# å¥½çš„åšæ³•: ä»é…ç½®è¯»å–
config = ConfigManager()
threshold = config.get_threshold("doc_similarity")

# å·®çš„åšæ³•: ç¡¬ç¼–ç 
threshold = 0.7
```

#### å°Šé‡æ’é™¤è§„åˆ™
```python
# æ£€æŸ¥æ‰€æœ‰æ’é™¤æ¡ä»¶
if (
    path in excluded_paths
    or any(is_subpath(path, d) for d in excluded_dirs)
    or ext in excluded_extensions
    or any(fnmatch(name, p) for p in excluded_patterns)
):
    skip_file()
```

### 5. æ—¥å¿—è®°å½•

#### åˆ†çº§æ—¥å¿—
```python
logger.debug("Detailed information for debugging")
logger.info("Normal operation information")
logger.warning("Warning about potential issues")
logger.error("Error that doesn't stop execution")
logger.critical("Critical error, cannot continue")
```

#### ä¸Šä¸‹æ–‡ä¿¡æ¯
```python
# å¥½çš„åšæ³•: åŒ…å«ä¸Šä¸‹æ–‡
logger.error(f"Failed to analyze {file_path}: {error}")

# å·®çš„åšæ³•: ç¼ºå°‘ä¸Šä¸‹æ–‡
logger.error(str(error))
```

### 6. ç±»å‹å®‰å…¨

#### ä½¿ç”¨ç±»å‹æ³¨è§£
```python
def analyze_file(
    file_path: str,
    force: bool = False
) -> Dict[str, Any]:
    ...
```

#### éªŒè¯æ•°æ®ç»“æ„
```python
# éªŒè¯å¿…éœ€å­—æ®µ
if "imports" not in analysis_result:
    analysis_result["imports"] = []
```

---

## æ€»ç»“

### æ¨¡å—å…³ç³»æ€»è§ˆ

```
project_analyzer (åè°ƒå™¨)
    â”‚
    â”œâ”€ è°ƒç”¨ key_manager (å¯†é’¥ç”Ÿæˆ)
    â”œâ”€ è°ƒç”¨ dependency_analyzer (æ–‡ä»¶åˆ†æ)
    â”‚   â””â”€ è¿”å› analysis_results
    â”‚
    â”œâ”€ è°ƒç”¨ symbol_map_merger (ç¬¦å·åˆå¹¶)
    â”‚   â””â”€ ç”Ÿæˆ project_symbol_map.json
    â”‚
    â”œâ”€ è°ƒç”¨ embedding_manager (åµŒå…¥ç”Ÿæˆ)
    â”‚   â”œâ”€ ä½¿ç”¨ project_symbol_map
    â”‚   â”œâ”€ ç”Ÿæˆ SES
    â”‚   â””â”€ ä¿å­˜ .npy æ–‡ä»¶
    â”‚
    â”œâ”€ è°ƒç”¨ dependency_suggester (ä¾èµ–å»ºè®®)
    â”‚   â”œâ”€ ä½¿ç”¨ analysis_results
    â”‚   â”œâ”€ ä½¿ç”¨ embeddings
    â”‚   â”œâ”€ ä½¿ç”¨ symbol_map
    â”‚   â””â”€ è¿”å› suggestions + ast_links
    â”‚
    â”œâ”€ è°ƒç”¨ tracker_io (è·Ÿè¸ªå™¨æ›´æ–°)
    â”‚   â””â”€ å†™å…¥ .md è·Ÿè¸ªå™¨æ–‡ä»¶
    â”‚
    â””â”€ è°ƒç”¨ visualize_dependencies (å¯è§†åŒ–)
        â””â”€ ç”Ÿæˆ .mermaid å›¾æ–‡ä»¶
```

### æ ¸å¿ƒæ•°æ®æµ

```
æºä»£ç æ–‡ä»¶
    â†“
[AST/Tree-sitteråˆ†æ]
    â†“
åˆ†æç»“æœ (imports, functions, classes, calls, ...)
    â†“
[ç¬¦å·æ˜ å°„åˆå¹¶]
    â†“
é¡¹ç›®ç¬¦å·æ˜ å°„ (ç»Ÿä¸€ç¬¦å·ç´¢å¼•)
    â†“
[åµŒå…¥å‘é‡ç”Ÿæˆ]
    â†“
å‘é‡è¡¨ç¤º (.npyæ–‡ä»¶)
    â†“
[ä¾èµ–å»ºè®®]
    â”œâ”€ ç»“æ„åŒ–ä¾èµ– (< / >)
    â”œâ”€ è¯­ä¹‰ä¾èµ– (s / S)
    â””â”€ æ–‡æ¡£ä¾èµ– (d)
    â†“
[å­—ç¬¦ä¼˜å…ˆçº§åˆå¹¶]
    â†“
æœ€ç»ˆä¾èµ–å»ºè®®
    â†“
[è·¯å¾„->å¯†é’¥è½¬æ¢]
    â†“
KEY#instanceæ ¼å¼
    â†“
[è·Ÿè¸ªå™¨æ›´æ–°]
    â†“
Markdownè·Ÿè¸ªå™¨æ–‡ä»¶
    â†“
[å¯è§†åŒ–]
    â†“
Mermaidä¾èµ–å›¾
```

### å…³é”®æŠ€æœ¯ç‚¹

1. **å¤šè¯­è¨€æ”¯æŒ**: AST (Python) + Tree-sitter (JS/TS/HTML/CSS)
2. **åŒé‡åˆ†æ**: ç»“æ„åŒ–(AST) + è¯­ä¹‰åŒ–(Embeddings)
3. **æ™ºèƒ½æ¨¡å‹é€‰æ‹©**: æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©Qwen3-4Bæˆ–mpnet
4. **Rerankerå¢å¼º**: Qwen3-Rerankeræå‡è¯­ä¹‰åŒ¹é…ç²¾åº¦
5. **ä¸‰çº§è·Ÿè¸ªå™¨**: Mini(æ¨¡å—) + Doc(æ–‡æ¡£) + Main(é¡¹ç›®)
6. **å­—ç¬¦ä¼˜å…ˆçº§**: æ˜ç¡®çš„ä¾èµ–ç±»å‹å±‚æ¬¡
7. **æ€§èƒ½ä¼˜åŒ–**: æ‰¹å¤„ç†ã€ç¼“å­˜ã€å¹¶è¡Œã€å…±äº«è®¡æ•°å™¨
8. **è·¯å¾„è¿ç§»**: æ”¯æŒå¯†é’¥å˜æ›´æ—¶çš„å¹³æ»‘è¿ç§»

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Claude Code
**æœ€åæ›´æ–°**: 2025-12-15
**ç‰ˆæœ¬**: 1.0.0
